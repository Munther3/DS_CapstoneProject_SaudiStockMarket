---
title: "Tadawul Future Prediction"
output: html_notebook
auther: "Munther Alnghenshi"
data: 12/15/2020
---
 
```{r}
if(!require(quantmod)) install.packages("quantmod")
if(!require(forecast)) install.packages("forecast")
if(!require(tseries)) install.packages("tseries")
if(!require(timeSeries)) install.packages("timeSeries")
if(!require(dplyr)) install.packages("dplyr")
if(!require(fGarch)) install.packages("fGarch")
if(!require(prophet)) install.packages("prophet")
if(!require(fUnitRoots)) install.packages("fUnitRoots")
if(!require(FitAR)) install.packages("FitAR")
if(!require(forecast)) install.packages("forecast")
library(FitAR)
library(forecast)
 
library(prophet)
library(quantmod)
library(forecast)
library(tseries)
library(timeSeries)
library(dplyr)
library(fGarch)
library(ggplot2)
```

## Overview:
* For this project I will start with a general idea of the market price, including dataset analysis. Followed by a general description and analysis of the dataset. The objective is to apply different forecasting predictive models for the Saudi stock market daily close price. The models will be evaluated, analysed and compared, following the main course project directions. For this evaluations I will focus in the train set accuracy performance of the models, trying to simplify our analysis due to our aim is showing new forecasting applications and encourage the open source use of them. 

* This report describes different time series and machine learning forecasting models applied to a Sadui stock market (Tadawuel) close price for he past 10 years, up untill the the end of last month data.  The data will be divided 70/30. I will divide into analyzing the first 7 years of the data going from 2010 - 2017, and leave the last 3 years (2017-2020) to compare the out come.


##### Displaying the head of the data

```{r, echo=FALSE, warning=FALSE, message=FALSE}

Stock <- read.csv("TadawulAnalysis.csv")

head(Stock) #show the head
```




## Data Cleaning 
* Dividing the data into  the first 7 years of the data going from 2010 - 2017, and leave the last 3 years (2017-2020) to compare the out come. The data will be divided 70/30.



```{r, echo=FALSE, warning=FALSE, message=FALSE}



dates <-  Stock$ï..Date #save the data column
dates <-  as.Date(dates, format = '%d/%m/%Y') #convert the date format 
values <- Stock$Price #saveing the closing prices
values <- as.factor(values) #convert the closing prices format to factors 

## train and test dates and values:
N = length(dates)
n = 0.7*N
traindates = dates[1:n]
testdates  = dates[(n+1):N]
trainvalues= values[1:n]
testvalues = values[(n+1):N]

ds <- Stock %>% 

  mutate_if(is.character, as.factor)


Stock[is.na(Stock)] <- 0 #assinging all NAs to ZERO if NA exists 
```


*Converting the data into time series data format. To do so we need to run the following command in R:


```{r}

close_price <- ts(ds[,2],start=2010,end =c(2020,11),frequency=12) #The ts() function will convert a numeric vector into an R time series object. 
head(close_price)
close_price_Train <- ts(ds[,2],start=2010,end =c(2017,11),frequency=12)  #data for first 7 years 
close_price_Test <- ts(ds[,2],start=c(2017,12),end =c(2020,11),frequency=12) #last 3 years
close_price_Train
```


*Where close_price is the univariate data which we are converting to time series. start gives the starting time of the data, in this case, its 2010 As it is a monthly data so ‘frequency=12’.


## Methods:

### ARIMA

#### Preliminary Analysis: 

* This is how the actual dataset looks like:
```{r}
autoplot(close_price_Train)+
  ggtitle("The closing price of TADAWUL")
  ylab("Traded in Saudi Riyal")
```

* We can infer from the graph itself that the data points follows an overall downward trend with some outliers in terms of sudden higher values. Now we need to do some analysis to find out the exact non-stationary and seasonality in the data.




#### Exploratory analysis
1. Autocorrelation analysis to examine serial dependence: Used to estimate which value in the past has a correlation with the current value. Provides the p,d,q estimate for ARIMA models.

2. Spectral analysis to examine cyclic behavior: Carried out to describe how variation in a time series may be accounted for by cyclic components. Also referred to as a Frequency Domain analysis. Using this, periodic components in a noisy environment can be separated out.

3. Trend estimation and decomposition: Used for seasonal adjustment. It seeks to construct, from an observed time series, a number of component series(that could be used to reconstruct the original series) where each of these has a certain characteristic.


*First, We need to understand the three components of a time series data:

1. Trend: A long-term change in the data is referred to as a trend. 

2. Seasonal: When a series is affected by some seasonal factors.

3. Cyclic: When data exhibit rises and falls that are not seasonal

*We can use the following R code to find out the components of this time series:
```{r}
components.ts = decompose(close_price_Train)
plot(components.ts)
```

*we get 4 components:

1. Observed – the actual data plot
2. Trend – the overall upward or downward movement of the data 
3. Seasonal – any seasonal pattern of the data 
4. Random – random part of the data

Next, we need to remove non-stationary part for ARIMA.

*To achieve stationarity:

1. Difference the data – compute the differences between consecutive observations
 


```{r}

tsstationary = diff(close_price_Train, differences=1) #Returns suitably lagged and iterated differences.
# the order of the difference = 1
plot(tsstationary)
#The closing price of TADAWUL vsTraded in Saudi Riyal
```

* To remove seasonality from the data, we subtract the seasonal component from the original series and then difference it to make it stationary.

* After removing seasonality and making the data stationary, it will look like:

```{r}
seasonality <- close_price_Train - components.ts$seasonal #we subtract the seasonal component from the original series
tsstationary <- diff(seasonality, differences=1) # difference it to make it stationary.
plot(tsstationary)
```



```{r}
#Box test 
Box.test(modelfit$residuals, type="Ljung-Box")
```





#### Fit the Arima model
 
1. We denote this forecasting model by ARIMA( p, d, q).
2.In ARIMA, p denotes the number of autoregressive terms, d denotes the number of times that the set should be differenciated for making it stationary. The last parameter q denotes the number of inve


* First we conduct an ADF, and PACF tests for the close price set:
```{r}
# Conduct ADF test for dataset
acf(tsstationary, lag.max=34) #The correlation between the observation at the current time spot and the observations at previous time spots. 

pacf(tsstationary, lag.max=34)
```

 
* The autocorrelation function (acf()) gives the autocorrelation at all possible lags 

* PACF() helps to identify the number of autoregression (AR) coefficients(p-value) in an ARIMA model.
 
  
 
 
 
#### AUTO.ARIMA fitting 

1. To better find the values of p,d,q we use the function auto.arima()

2. The auto.arima() function in R uses a combination of unit root tests, minimization of the AIC and MLE to obtain an ARIMA model.

3. What is AIC? Akaike's Information Criterion (AIC), which was useful in selecting predictors for regression, is also useful for determining the order of an ARIMA model.

4. The p,d, and q are then chosen by least value of AIC.  




```{r}
modelfit <- auto.arima(tsstationary, trace=TRUE) 
```
 

 


#### Arima Results:

* As we can see, the AUTO-ARIMA selects the best model parameters, giving us a very good estimation.

* I focus on forecasting the close stock price for the next 3 years so that I can compare the outcome with the test data, which has the data for the targeted period by the model 

```{r}
#Dataset forecasting for the next 3 years

price_forecast <- forecast(modelfit, h=36) #unit time = 1 month 
accuracy(price_forecast,close_price_Test) #testing the accuracy of ARIMA 
```

* Forecasting the close market price.

* The blue line that represents the mean of our prediction for nest 3 years.

* We can see plotting the test data (2017-2020) the outcome of the forecast is 

```{r}
#Dataset forecasting plot for the next 365 days
plot(price_forecast)
autoplot(close_price_Test)+ #test the future 3 years
  ggtitle("The closing price of TADAWUL")
  ylab("Traded in Saudi Riyal")
```

*The forecasts are shown as a blue line, with the 80% prediction intervals as a dark shaded area, and the 95% prediction intervals as a light shaded area.

*This is the overall process by which we can analyze time series data and forecast values from existing series using ARIMA.
```{r}
#Dataset forecast lower first 5 values AND upper
head(price_forecast$lower)
head(price_forecast$upper)

```
```{r}
#Dividing the data into train and test, applying the model
N = length(close_price)
n = 0.7*N
train = close_price[1:n]
test  = close_price[(n+1):N]
trainarimafit <- auto.arima(train, lambda = "auto")
predlen=length(test)
trainarimafit <- forecast(trainarimafit, h=predlen)
 
```


```{r}
#Plotting mean predicted values vs real data
meanvalues <- as.vector(trainarimafit$mean)
precios <- as.vector(test)
plot(meanvalues, type= "l", col= "red")
lines(precios, type = "l")
```



* In the red line we see our mean forecasting prediction tendency over the real close price of the market. The tendency shows a good approach predicting the future direction of the close price.

 


 

## Prophet:
* The origin of prophet comes from the application of a forecasting model into supply chain management, sales and economics. This model helps with a statistical approach in shaping business decisions.The Prophet model has been developed by Facebook’s Core Data Science team and it is an open-source tool for business forecasting.
\
\
\
*Prophet forecast flow:
\

$y(t)=g(t)+s(t)+h(t)+ϵ$

\
* The Prophet model is an additive model with the components g(t) models trends, s(t) models seasonality with Fourier series, h(t) effects of holidays or large events.
\
\
\


* The fist step before forecasting using prophet is to convert the dataset into the format that Prophet input requires.
* Prophet expects input data to have 2 columns, ds and y.
```{r}
N = length(dates)
n = 0.3*N
proph <- data.frame(ds = dates[(n+1):N], #adding the two columns of dates and prices to a data
                 y = values[(n+1):N])
proph
model1 <- prophet(proph) #Once we have converted the data we can proceed to apply the model with the dataset and predict future values.

future <- make_future_dataframe(model1, periods = 365*3) # predicting a year 
forecast_prophet <- predict(model1, future)
dyplot.prophet(model1,forecast_prophet)
```


* With the model applied and the forecast plotted we proceed to calculate the model performance.
```{r}
#Creating train prediction datset to compare the real data
dataprediction <- data.frame(forecast_prophet$ds,forecast_prophet$yhat)
trainlen <- length(close_price)
dataprediction <- dataprediction[c(1:trainlen),]
#Once we have created our dataset to compare the real data against the predicted values y hat we proceed to calculate de accuracy.
```
```{r}
#Creating cross validation 
accuracy(dataprediction$forecast_prophet.y,model1$y)
#Creating cross validation 
prophet_plot_components(model1,forecast_prophet)
```


## Feed Foward Neural network

* Researching deeply in new machine learning models I have reached some new neural network function in the forecast package called nneta

* A single hidden layer neural network is the most simple neural networks form. In this single hidden layer form there is only one layer of input nodes that send weighted inputs to a subsequent layer of receiving nodes. This nnetar function in the forecast package fits a single hidden layer neural network model to a timeseries. The function model approach is to use lagged values of the time series as input data, reaching to a non-linear autoregressive model.


```{r}
#Hidden layers creation

#With the hidden layers approach explained we proceed to calculate them:

alpha <- 1.5^(-10)
hn <- length(close_price)/(alpha*(length(close_price)+30))
```

* with the hidden layers calculated we proceed to apply the nnetar function with the parameters selected.

```{r}
#Fitting nnetar

#
lambda <- BoxCox.lambda(close_price)
dnn_pred <- nnetar(close_price_Train, size= hn, lambda = lambda)
```




```{r}
#Fitting nnetar
dnn_forecast <- forecast(dnn_pred, h= 36, PI = TRUE) #forcast from 2017-2020 
plot(dnn_forecast)
```

```{r}
accuracy(dnn_forecast,close_price_Test)
```



## Conclusion:
* In this study I focused in the application of different models, learning how to use them with the objective to forecast new price values. As we can see from the results, the models performed with similar future tendency predictions. All the models predicted a tendency of a lower price in next 3 years. We can conclude that the ARIMA and prophet performed very well inside the prediction intervals and the accuracy metrics. The Neural Net models model did not performed as well as ARIMA or prophet models. Maybe it needed more tuning for getting more accurated results.